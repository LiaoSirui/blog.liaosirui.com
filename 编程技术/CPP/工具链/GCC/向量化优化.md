## 什么是自动向量化？

自动向量化（automatic vectorization）是自动并行化（automatic parallelization）的一种特殊情况，它将一次处理一对的标量运算转换为一次并行处理多对的向量运算。因此向量化可以显着加速一些带循环的程序运算，尤其是在大型数据集上。根据 arch 信息，编译器优化的目标可以是 Intel 或 AMD 处理器中的 SSE*、AVX/AVX2 或更高级的指令，或 ARM 处理器中的 NEON 指令

## 什么是 SIMD 指令？

SIMD（Single instruction, multiple data）单指令多数据技术能对程序中数据进行并行处理，提高吞吐量。它将原来需要多次装载的数据一次性装载到向量寄存器，即 SIMD 指令允许在一个步骤中处理多个数据。现代的 CPU 设计都包括 SIMD 指令，以提高多媒体程序和科学计算程序的性能，但 SIMD 与利用线程的 SIMT 不同

SIMD 指令的首次使用是在 1966 年，它一般分为两种：

- 手工向量化：通过内嵌汇编码或编译器提供的内函数来添加 SIMD 指令

- 自动向量化：利用编译器分析串行程序中控制流和数据流的特征，识别程序中可以向量执行的部分，将标量语句自动转换为相应的 SIMD 向量语句

## 机器支持哪些指令集？

```bash
cat /proc/cpuinfo

# flags 字段
```

注意：向量化的操作需要机器硬件的支持

```bash
gcc -c -Q -march=native --help=target
```

## Intel

- MMX 指令

MultiMedia eXtensions（MMX），MMX指令主要使用的寄存器为MM0 ~ MM7，与浮点运算不能同时进行。MMX指令能一次性地操作1个64-bit的数据、或者两个32-bit的数据、或者4个16-bit的数据、或者8个8-bit的数据

MMX指令集的扩展包括：3DNow!、SSE、AVX

- SSE 指令

Streaming SIMD eXtensions（SSE），SSE指令采用了独立的寄存器组XMM0 ~ XMM7，64位模式下为XMM0 ~ XMM15，并且这些寄存器的长度也增加到了128-bit

SSE指令的升级版包括：SSE2/SSE3/SSSE3/SSE4

- AVX/AVX2 指令

Advanced Vector eXtentions（AVX），AVX对XMM寄存器做了扩展，从原来的128-bit扩展到了256-bit，并从XMM0–XMM7重命名为YMM0–YMM7，仍可通过SSE指令对YMM寄存器的低128位进行操作。新指令使用英特尔所谓的VEX前缀进行编码，这是一个两字节或三字节的前缀，旨在消除当前和将来的x86/x64指令编码的复杂性。AVX2将大多数整数命令扩展为256位，并引入了融合的乘加（FMA）操作。

- FMA 指令

Fused-Multiply-Add（FMA），FMA指令集是128-bit和256-bit的SSE的扩展指令集，以进行乘加运算。共有两种变体：FMA4、FMA3，自2014年以来，从PILEDRIVER架构开始，AMD处理器就支持FMA3；从Haswell处理器和Broadwell处理器开始，英特尔则支持FMA

- AVX512* 指令

英特尔架构处理器支持旧式和现代指令集，从64位MMX扩展到新的512位指令AVX-512。ZMM的低256-bit与YMM混用。ZMM的前缀为EVEX。与AVX / AVX2相比，AVX-512最显着的新功能是512位矢量寄存器宽度

- 其他指令

KNC等其他指令集



Intel 不同架构向量化指令集如下：



## 参考资料

- <https://blog.csdn.net/qq_36287943/article/details/105202721>
